{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a38eb7ae-3f15-492a-8054-328f803c0a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b912fc91-7cac-48d1-8f48-cfd393600708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "IMG_EXT = ['png', 'jpg', 'jpeg', 'bmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "450150c2-36cf-4203-92ec-24b873e9cac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "990ed909-7446-4c54-90e2-aec5cb8ce2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img_class in os.listdir(DATA_DIR):\n",
    "    for image in os.listdir(os.path.join(DATA_DIR, img_class)):\n",
    "        image_path = os.path.join(DATA_DIR, img_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in IMG_EXT:\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(f'Issue with {image_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8c55005c-4499-4775-9d64-1701d7af4e54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "88b96a7d-0248-43e7-8b3a-3b382a478e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.Resize((255, 255)),\n",
    "                                            torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b6d31291-7cfa-4757-8768-7aeb9b66078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchvision.datasets.ImageFolder(DATA_DIR, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "36270a4e-61be-4065-afac-7f394c1eec2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9d060db7-db47-4287-9cfb-168986b22715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset=data,\n",
    "                                         batch_size=23,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "826ee2fe-c583-4d81-bce7-41473f382f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3541ec9a-7c17-4e3b-b4db-1f40f72fd80d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen1 = torch.Generator().manual_seed(69)\n",
    "train_set, test_set, val_set = torch.utils.data.random_split(dataloader, [0.7, 0.15, 0.15], generator=gen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "48edcd7f-9a4e-47e9-a927-73cfbb13965c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d7395555-fd0a-4c03-8dff-3f4ca98b7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "68b64b7f-d1d4-453d-b774-d517eca9874c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([23, 3, 255, 255]), torch.Size([23]))"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "0d916b8d-497f-4b41-b3cb-a8b69f64c684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1_block = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv2_block = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv3_block = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "        \n",
    "        self.dense_block = nn.Sequential(\n",
    "            nn.Linear(16 * 30 * 30 , 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1_block(x)\n",
    "        x = self.conv2_block(x)\n",
    "        x = self.conv3_block(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_block(x)\n",
    "        return self.output(x).reshape((23))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "8726b8a6-84c0-4607-a02a-1ce27fb07ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "e746f6d8-6957-4309-a3ff-ce0e2920579a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "b8665e20-f613-4c9c-8b88-4b98104d26db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1_block): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2_block): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3_block): Sequential(\n",
      "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (dense_block): Sequential(\n",
      "    (0): Linear(in_features=14400, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "988be0f1-359e-4e40-ae48-99d54ab3a3e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "366e5d99-8fca-41d4-becc-19aba0379104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_nn(epochs, net : torch.nn.Module, \n",
    "             train_set : torch.utils.data.DataLoader,\n",
    "             val_set : torch.utils.data.DataLoader) -> (torch.nn.Module, list, list):\n",
    "    \n",
    "    net.train()                                              # Set the NN to training mode.\n",
    "    \n",
    "    epoch_count, train_loss_vals, val_loss_vals = [], [], [] # List that will be used to check model performance\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        for x_batch, y_batch in train_set.dataset:           # Joint the corresponding batches and unwrap them\n",
    "            y_batch = y_batch.type(torch.float32)\n",
    "            y_pred = net(x_batch)                            # Make predictions for the current batch\n",
    "            loss = loss_fn(y_pred, y_batch)                  # Compute the loss of the predictions\n",
    "            optimizer.zero_grad()                            # Reset the gradients\n",
    "            loss.backward()                                  # Perform the backpropagation\n",
    "            optimizer.step()                                 # Optimize the model\n",
    "            \n",
    "        for data, labels in val_set.dataset:\n",
    "            labels = labels.type(torch.float32)\n",
    "            preds = net(data)\n",
    "            val_loss = loss_fn(preds, labels)\n",
    "    \n",
    "        # if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)                            \n",
    "        train_loss_vals.append(loss)\n",
    "        print(f\"Epoch {epoch}: Train loss of {loss}; Validation loss of {val_loss}\")\n",
    "        # print(net.state_dict())                            # Bad idea, the state_dict is huge\n",
    "            \n",
    "    return net, epoch_count, train_loss_vals, val_loss_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "6096552a-0708-483c-baf9-f63f2d07bd89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train loss of 0.2499009370803833; Validation loss of 0.2870894968509674\n",
      "Epoch 1: Train loss of 0.32643401622772217; Validation loss of 0.3261356055736542\n",
      "Epoch 2: Train loss of 0.19381608068943024; Validation loss of 0.2981284260749817\n",
      "Epoch 3: Train loss of 0.23232491314411163; Validation loss of 0.27362969517707825\n",
      "Epoch 4: Train loss of 0.23079146444797516; Validation loss of 0.2524832785129547\n",
      "Epoch 5: Train loss of 0.307251513004303; Validation loss of 0.1434963196516037\n",
      "Epoch 6: Train loss of 0.2229301482439041; Validation loss of 0.24234504997730255\n",
      "Epoch 7: Train loss of 0.2980499267578125; Validation loss of 0.17894232273101807\n",
      "Epoch 8: Train loss of 0.2740064561367035; Validation loss of 0.21621140837669373\n",
      "Epoch 9: Train loss of 0.23137404024600983; Validation loss of 0.27588745951652527\n",
      "Epoch 10: Train loss of 0.2471102476119995; Validation loss of 0.2658098340034485\n",
      "Epoch 11: Train loss of 0.16848936676979065; Validation loss of 0.17722778022289276\n",
      "Epoch 12: Train loss of 0.29558253288269043; Validation loss of 0.20431464910507202\n",
      "Epoch 13: Train loss of 0.21848587691783905; Validation loss of 0.14559730887413025\n",
      "Epoch 14: Train loss of 0.23315493762493134; Validation loss of 0.23295149207115173\n",
      "Epoch 15: Train loss of 0.1590975522994995; Validation loss of 0.2296680212020874\n",
      "Epoch 16: Train loss of 0.24390877783298492; Validation loss of 0.19156955182552338\n",
      "Epoch 17: Train loss of 0.2076430320739746; Validation loss of 0.1894952803850174\n",
      "Epoch 18: Train loss of 0.16976599395275116; Validation loss of 0.1862751692533493\n",
      "Epoch 19: Train loss of 0.28357356786727905; Validation loss of 0.20032227039337158\n",
      "Epoch 20: Train loss of 0.21417513489723206; Validation loss of 0.16588585078716278\n",
      "Epoch 21: Train loss of 0.17880038917064667; Validation loss of 0.16251754760742188\n",
      "Epoch 22: Train loss of 0.12837620079517365; Validation loss of 0.1764000803232193\n",
      "Epoch 23: Train loss of 0.20546980202198029; Validation loss of 0.1895369291305542\n",
      "Epoch 24: Train loss of 0.17146864533424377; Validation loss of 0.1925704926252365\n",
      "Epoch 25: Train loss of 0.12340688705444336; Validation loss of 0.18453387916088104\n",
      "Epoch 26: Train loss of 0.16684888303279877; Validation loss of 0.22739559412002563\n",
      "Epoch 27: Train loss of 0.20329029858112335; Validation loss of 0.1346575915813446\n",
      "Epoch 28: Train loss of 0.13282909989356995; Validation loss of 0.20653937757015228\n",
      "Epoch 29: Train loss of 0.18933287262916565; Validation loss of 0.20019648969173431\n",
      "Epoch 30: Train loss of 0.12935718894004822; Validation loss of 0.15799033641815186\n",
      "Epoch 31: Train loss of 0.21179701387882233; Validation loss of 0.11383888870477676\n",
      "Epoch 32: Train loss of 0.16792114078998566; Validation loss of 0.16781853139400482\n",
      "Epoch 33: Train loss of 0.165848508477211; Validation loss of 0.09661080688238144\n",
      "Epoch 34: Train loss of 0.19092728197574615; Validation loss of 0.09544870257377625\n",
      "Epoch 35: Train loss of 0.06743746995925903; Validation loss of 0.17470073699951172\n",
      "Epoch 36: Train loss of 0.23062463104724884; Validation loss of 0.1857372373342514\n",
      "Epoch 37: Train loss of 0.1441548615694046; Validation loss of 0.17028582096099854\n",
      "Epoch 38: Train loss of 0.11656608432531357; Validation loss of 0.23266670107841492\n",
      "Epoch 39: Train loss of 0.1787949502468109; Validation loss of 0.19990350306034088\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[329], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_model, epoch_l, train_loss_l, val_loss_l \u001b[38;5;241m=\u001b[39m train_nn(\u001b[38;5;241m40\u001b[39m, model, train_set, val_set)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "trained_model, epoch_l, train_loss_l, val_loss_l = train_nn(40, model, train_set, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b95d43-db1c-48ff-b1f4-1297edc426f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
