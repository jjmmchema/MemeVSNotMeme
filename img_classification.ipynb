{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "a38eb7ae-3f15-492a-8054-328f803c0a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b912fc91-7cac-48d1-8f48-cfd393600708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "IMG_EXT = ['png', 'jpg', 'jpeg', 'bmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "450150c2-36cf-4203-92ec-24b873e9cac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "990ed909-7446-4c54-90e2-aec5cb8ce2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img_class in os.listdir(DATA_DIR):\n",
    "    for image in os.listdir(os.path.join(DATA_DIR, img_class)):\n",
    "        image_path = os.path.join(DATA_DIR, img_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in IMG_EXT:\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(f'Issue with {image_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8c55005c-4499-4775-9d64-1701d7af4e54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "88b96a7d-0248-43e7-8b3a-3b382a478e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.Resize((255, 255)),\n",
    "                                            torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b6d31291-7cfa-4757-8768-7aeb9b66078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchvision.datasets.ImageFolder(DATA_DIR, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "36270a4e-61be-4065-afac-7f394c1eec2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9d060db7-db47-4287-9cfb-168986b22715",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset=data,\n",
    "                                         batch_size=23,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "826ee2fe-c583-4d81-bce7-41473f382f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3541ec9a-7c17-4e3b-b4db-1f40f72fd80d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen1 = torch.Generator().manual_seed(69)\n",
    "train_set, test_set, val_set = torch.utils.data.random_split(dataloader, [0.7, 0.15, 0.15], generator=gen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "48edcd7f-9a4e-47e9-a927-73cfbb13965c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d7395555-fd0a-4c03-8dff-3f4ca98b7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "68b64b7f-d1d4-453d-b774-d517eca9874c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([23, 3, 255, 255]), torch.Size([23]))"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "0d916b8d-497f-4b41-b3cb-a8b69f64c684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1_block = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv2_block = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv3_block = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "        \n",
    "        self.dense_block = nn.Sequential(\n",
    "            nn.Linear(16 * 30 * 30 , 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1_block(x)\n",
    "        x = self.conv2_block(x)\n",
    "        x = self.conv3_block(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_block(x)\n",
    "        return self.output(x).reshape((23))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "8726b8a6-84c0-4607-a02a-1ce27fb07ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "e746f6d8-6957-4309-a3ff-ce0e2920579a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "b8665e20-f613-4c9c-8b88-4b98104d26db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1_block): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2_block): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3_block): Sequential(\n",
      "    (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (dense_block): Sequential(\n",
      "    (0): Linear(in_features=14400, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "988be0f1-359e-4e40-ae48-99d54ab3a3e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "366e5d99-8fca-41d4-becc-19aba0379104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_nn(epochs, net : torch.nn.Module, \n",
    "             train_set : torch.utils.data.DataLoader,\n",
    "             val_set : torch.utils.data.DataLoader) -> (torch.nn.Module, list, list):\n",
    "    \n",
    "    net.train()                                              # Set the NN to training mode.\n",
    "    \n",
    "    epoch_count, train_loss_vals, val_loss_vals = [], [], [] # List that will be used to check model performance\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        for x_batch, y_batch in train_set.dataset:           # Joint the corresponding batches and unwrap them\n",
    "            y_batch = y_batch.type(torch.float32)\n",
    "            y_pred = net(x_batch)                            # Make predictions for the current batch\n",
    "            loss = loss_fn(y_pred, y_batch)                  # Compute the loss of the predictions\n",
    "            optimizer.zero_grad()                            # Reset the gradients\n",
    "            loss.backward()                                  # Perform the backpropagation\n",
    "            optimizer.step()                                 # Optimize the model\n",
    "            \n",
    "        for data, labels in val_set.dataset:\n",
    "            labels = labels.type(torch.float32)\n",
    "            preds = net(data)\n",
    "            val_loss = loss_fn(preds, labels)\n",
    "    \n",
    "        # if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)                            \n",
    "        train_loss_vals.append(loss)\n",
    "        print(f\"Epoch {epoch}: Train loss of {loss}; Validation loss of {val_loss}\")\n",
    "        # print(net.state_dict())                            # Bad idea, the state_dict is huge\n",
    "            \n",
    "    return net, epoch_count, train_loss_vals, val_loss_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "6096552a-0708-483c-baf9-f63f2d07bd89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss of 0.16391213238239288; Validation loss of 0.1638289839029312\n",
      "Epoch 2: Train loss of 0.11198284476995468; Validation loss of 0.09948591887950897\n",
      "Epoch 3: Train loss of 0.1106095090508461; Validation loss of 0.14731965959072113\n",
      "Epoch 4: Train loss of 0.14560066163539886; Validation loss of 0.1697155088186264\n",
      "Epoch 5: Train loss of 0.11979208886623383; Validation loss of 0.10770679265260696\n",
      "Epoch 6: Train loss of 0.13009917736053467; Validation loss of 0.13000795245170593\n",
      "Epoch 7: Train loss of 0.17964421212673187; Validation loss of 0.15168210864067078\n",
      "Epoch 8: Train loss of 0.16142290830612183; Validation loss of 0.1038544774055481\n",
      "Epoch 9: Train loss of 0.18612799048423767; Validation loss of 0.2118360549211502\n",
      "Epoch 10: Train loss of 0.12371081113815308; Validation loss of 0.13608869910240173\n",
      "Epoch 11: Train loss of 0.14933842420578003; Validation loss of 0.13440237939357758\n",
      "Epoch 12: Train loss of 0.08803573995828629; Validation loss of 0.0882875919342041\n",
      "Epoch 13: Train loss of 0.11927232891321182; Validation loss of 0.10873619467020035\n",
      "Epoch 14: Train loss of 0.13044212758541107; Validation loss of 0.1435217559337616\n",
      "Epoch 15: Train loss of 0.17073261737823486; Validation loss of 0.09565433114767075\n",
      "Epoch 16: Train loss of 0.10507357865571976; Validation loss of 0.1476719230413437\n",
      "Epoch 17: Train loss of 0.1344938427209854; Validation loss of 0.1240382194519043\n",
      "Epoch 18: Train loss of 0.22196325659751892; Validation loss of 0.12260837107896805\n",
      "Epoch 19: Train loss of 0.1315026879310608; Validation loss of 0.10082104057073593\n",
      "Epoch 20: Train loss of 0.0797370970249176; Validation loss of 0.06972628831863403\n",
      "Epoch 21: Train loss of 0.06899747997522354; Validation loss of 0.09856928139925003\n",
      "Epoch 22: Train loss of 0.15741728246212006; Validation loss of 0.1263868659734726\n",
      "Epoch 23: Train loss of 0.09611745178699493; Validation loss of 0.08644969761371613\n",
      "Epoch 24: Train loss of 0.06649401038885117; Validation loss of 0.16575010120868683\n",
      "Epoch 25: Train loss of 0.1220141276717186; Validation loss of 0.09380316734313965\n",
      "Epoch 26: Train loss of 0.12057561427354813; Validation loss of 0.11123309284448624\n",
      "Epoch 27: Train loss of 0.13761399686336517; Validation loss of 0.10074464976787567\n",
      "Epoch 28: Train loss of 0.10871277004480362; Validation loss of 0.06356485188007355\n",
      "Epoch 29: Train loss of 0.10744457691907883; Validation loss of 0.07158544659614563\n",
      "Epoch 30: Train loss of 0.10616054385900497; Validation loss of 0.13261692225933075\n",
      "Epoch 31: Train loss of 0.11367194354534149; Validation loss of 0.10485434532165527\n",
      "Epoch 32: Train loss of 0.07777705788612366; Validation loss of 0.09501685202121735\n",
      "Epoch 33: Train loss of 0.07687285542488098; Validation loss of 0.10243730247020721\n",
      "Epoch 34: Train loss of 0.06755577772855759; Validation loss of 0.10125716030597687\n",
      "Epoch 35: Train loss of 0.1001618430018425; Validation loss of 0.12513084709644318\n",
      "Epoch 36: Train loss of 0.10726545006036758; Validation loss of 0.07421838492155075\n",
      "Epoch 37: Train loss of 0.09789658337831497; Validation loss of 0.08154617995023727\n",
      "Epoch 38: Train loss of 0.08065604418516159; Validation loss of 0.08867193013429642\n",
      "Epoch 39: Train loss of 0.0877363383769989; Validation loss of 0.07173535227775574\n",
      "Epoch 40: Train loss of 0.0946149080991745; Validation loss of 0.07879780232906342\n"
     ]
    }
   ],
   "source": [
    "trained_model, epoch_l, train_loss_l, val_loss_l = train_nn(40, model, train_set, val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "19b95d43-db1c-48ff-b1f4-1297edc426f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "8a518935-fa92-4aff-80f8-bb6d0993d36d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = Path('MODELS')\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "fa57e372-45c9-4098-9c19-b2434e67bcb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'trained_model_1.pth'\n",
    "MODEL_PATH = MODEL_DIR / MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b9eee-afd8-41c6-a83c-7fcd844fc666",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=trained_model.state_dict(),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d927f6f-417f-460a-a570-a4de9b64c85d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
